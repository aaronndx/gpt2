{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Jxw6hhqF1Nst",
      "metadata": {
        "id": "Jxw6hhqF1Nst"
      },
      "source": [
        "# Colab to test gpt2 training and inference\n",
        "1. Add GPU in Runtime\n",
        "2. Click \"Run all\" to copy github repo and run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ZSB5rh81YkD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZSB5rh81YkD",
        "outputId": "6b42d80c-f929-41f5-8e5a-abb76e52cbd5"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aaronndx/gpt2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q7tmpsWa1zXA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7tmpsWa1zXA",
        "outputId": "930fea30-4258-4b3a-e848-08b7960ffe09"
      },
      "outputs": [],
      "source": [
        "%cd gpt2/\n",
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LbknReRB16h3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbknReRB16h3",
        "outputId": "043d674e-5a6a-48f3-9123-9fe84401db9b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212Py56W2LlC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "212Py56W2LlC",
        "outputId": "e9dced11-70f3-414a-dca0-751d4b0d3089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from train_gpt2 import efficient_train, simple_eval\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aKRCyPQV2WV2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKRCyPQV2WV2",
        "outputId": "6de2bb33-2a9f-4e13-8e1f-fdafe42840dc"
      },
      "outputs": [],
      "source": [
        "model = efficient_train(device, data_repo_id=\"aaronndx/fineweb-edu-10B-shards\", steps=300, B=16, T=1024, total_batch_size=2**19, log_dir=\"log\", compile=True, eval_every=100, restore_repo_id = \"aaronndx/gpt2_checkpoints\", restore_from_ckpt_filename='gpt2_aug_30_step_0100.bin', save_repo_id=\"aaronndx/gpt2_checkpoints\", save_ckpt_every=100, eval_with_hellaswag=False, fast_learning=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "uzNDKPRh5S7K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzNDKPRh5S7K",
        "outputId": "d1b6960d-83ad-42f0-d678-48f0726b6da4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model loaded successfully!\n",
            "Output 1: If I should tell thee o'er this thy day's work,\n",
            "And not have made my soul like no brother?\n",
            "Come more in heaven, do have these life.\n",
            "I\n",
            "If you,\n",
            "My brother, as that 'tis\n",
            "Output 2: If I should tell thee o'er this thy day's work, sir,\n",
            "That in the guilt of one; but which that\n",
            "As be do prepared\n",
            "So yet; which I\n",
            "And 'tis that the name and come; would keep\n",
            "Output 3: If I should tell thee o'er this thy day's work,\n",
            "That would do say but my brother, and I were with joy\n",
            "Of them for all, and if that do thetwath very poor vice?\n",
            "Let'stis most\n",
            "Output 4: If I should tell thee o'er this thy day's work,\n",
            "So place.\n",
            "\n",
            "ANGELO:\n",
            "Not to your high offence? And's face? Even\n",
            "And they's son?\n",
            "\n",
            "Is brother,\n",
            "\n",
            "\n",
            "\n",
            "Output 5: If I should tell thee o'er this thy day's work,\n",
            "And let mine own body:\n",
            "And how let us be not't,\n",
            "To do hear me for thy deeds that me with myall you are be do to theT\n"
          ]
        }
      ],
      "source": [
        "simple_eval(device, max_length=50, input=\"If I should tell thee o'er this thy day's work,\", model=model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
